<!doctype html><html lang=en dir=auto><head><meta charset=utf-8><meta http-equiv=X-UA-Compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><title>Infografia Redes Neuronales | Ancordss-Blog!</title>
<meta name=keywords content="fast,Blogging"><meta name=description content="I. Introducción: El Ecosistema de la Inteligencia Artificial y la Configuración del Entorno Práctico A. Contextualización y Definiciones Fundamentales El &ldquo;Curso intensivo de redes neuronales&rdquo; impartido por Irving Vasquez 1 constituye una exploración estructurada de los fundamentos teóricos y prácticos que sustentan el campo moderno de la inteligencia artificial. Para navegar este dominio, el curso establece, en primer lugar, una jerarquía conceptual precisa, distinguiendo entre los términos que a menudo se usan indistintamente."><meta name=author content="Ancordss"><link rel=canonical href=https://ancordss.github.io/post/ia/><link crossorigin=anonymous href=/assets/css/stylesheet.min.d6e3b908b0057e207d7a03f785a6dc7aabf91f7483df0b5b295729600dfb6b93.css integrity="sha256-1uO5CLAFfiB9egP3habceqv5H3SD3wtbKVcpYA37a5M=" rel="preload stylesheet" as=style><link rel=icon href=https://ancordss.github.io/favicon.ico><link rel=icon type=image/png sizes=16x16 href=https://ancordss.github.io/favicon-16x16.png><link rel=icon type=image/png sizes=32x32 href=https://ancordss.github.io/favicon-32x32.png><link rel=apple-touch-icon href=https://ancordss.github.io/apple-touch-icon.png><link rel=mask-icon href=https://ancordss.github.io/safari-pinned-tab.svg><meta name=theme-color content="#2e2e33"><meta name=msapplication-TileColor content="#2e2e33"><link rel=alternate hreflang=en href=https://ancordss.github.io/post/ia/><noscript><style>#theme-toggle,.top-link{display:none}</style><style>@media(prefers-color-scheme:dark){:root{--theme:rgb(29, 30, 32);--entry:rgb(46, 46, 51);--primary:rgb(218, 218, 219);--secondary:rgb(155, 156, 157);--tertiary:rgb(65, 66, 68);--content:rgb(196, 196, 197);--hljs-bg:rgb(46, 46, 51);--code-bg:rgb(55, 56, 62);--border:rgb(51, 51, 51)}.list{background:var(--theme)}.list:not(.dark)::-webkit-scrollbar-track{background:0 0}.list:not(.dark)::-webkit-scrollbar-thumb{border-color:var(--theme)}}</style></noscript><script>var doNotTrack=!1;doNotTrack||(function(e,t,n,s,o,i,a){e.GoogleAnalyticsObject=o,e[o]=e[o]||function(){(e[o].q=e[o].q||[]).push(arguments)},e[o].l=1*new Date,i=t.createElement(n),a=t.getElementsByTagName(n)[0],i.async=1,i.src=s,a.parentNode.insertBefore(i,a)}(window,document,"script","https://www.google-analytics.com/analytics.js","ga"),ga("create","UA-123-45","auto"),ga("send","pageview"))</script><meta property="og:title" content="Infografia Redes Neuronales"><meta property="og:description" content="I. Introducción: El Ecosistema de la Inteligencia Artificial y la Configuración del Entorno Práctico A. Contextualización y Definiciones Fundamentales El &ldquo;Curso intensivo de redes neuronales&rdquo; impartido por Irving Vasquez 1 constituye una exploración estructurada de los fundamentos teóricos y prácticos que sustentan el campo moderno de la inteligencia artificial. Para navegar este dominio, el curso establece, en primer lugar, una jerarquía conceptual precisa, distinguiendo entre los términos que a menudo se usan indistintamente."><meta property="og:type" content="article"><meta property="og:url" content="https://ancordss.github.io/post/ia/"><meta property="og:image" content="https://avatars.githubusercontent.com/u/87324382?s=400&amp;u=3a0cbb2958a9346ac0d43164be8903afb12a511e&amp;v=4"><meta property="article:section" content="post"><meta property="article:published_time" content="2025-10-24T22:18:56+00:00"><meta property="article:modified_time" content="2025-10-24T22:18:56+00:00"><meta property="og:site_name" content="James-Maradiaga"><meta name=twitter:card content="summary_large_image"><meta name=twitter:image content="https://avatars.githubusercontent.com/u/87324382?s=400&amp;u=3a0cbb2958a9346ac0d43164be8903afb12a511e&amp;v=4"><meta name=twitter:title content="Infografia Redes Neuronales"><meta name=twitter:description content="I. Introducción: El Ecosistema de la Inteligencia Artificial y la Configuración del Entorno Práctico A. Contextualización y Definiciones Fundamentales El &ldquo;Curso intensivo de redes neuronales&rdquo; impartido por Irving Vasquez 1 constituye una exploración estructurada de los fundamentos teóricos y prácticos que sustentan el campo moderno de la inteligencia artificial. Para navegar este dominio, el curso establece, en primer lugar, una jerarquía conceptual precisa, distinguiendo entre los términos que a menudo se usan indistintamente."><script type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"Posts","item":"https://ancordss.github.io/post/"},{"@type":"ListItem","position":2,"name":"Infografia Redes Neuronales","item":"https://ancordss.github.io/post/ia/"}]}</script><script type=application/ld+json>{"@context":"https://schema.org","@type":"BlogPosting","headline":"Infografia Redes Neuronales","name":"Infografia Redes Neuronales","description":"I. Introducción: El Ecosistema de la Inteligencia Artificial y la Configuración del Entorno Práctico A. Contextualización y Definiciones Fundamentales El \u0026ldquo;Curso intensivo de redes neuronales\u0026rdquo; impartido por Irving Vasquez 1 constituye una exploración estructurada de los fundamentos teóricos y prácticos que sustentan el campo moderno de la inteligencia artificial. Para navegar este dominio, el curso establece, en primer lugar, una jerarquía conceptual precisa, distinguiendo entre los términos que a menudo se usan indistintamente.","keywords":["fast","Blogging"],"articleBody":"I. Introducción: El Ecosistema de la Inteligencia Artificial y la Configuración del Entorno Práctico A. Contextualización y Definiciones Fundamentales El “Curso intensivo de redes neuronales” impartido por Irving Vasquez 1 constituye una exploración estructurada de los fundamentos teóricos y prácticos que sustentan el campo moderno de la inteligencia artificial. Para navegar este dominio, el curso establece, en primer lugar, una jerarquía conceptual precisa, distinguiendo entre los términos que a menudo se usan indistintamente.2\nLa Inteligencia Artificial (IA) se presenta como el campo más amplio, una disciplina de la informática dedicada a crear sistemas que pueden simular tareas que normalmente requieren inteligencia humana. Dentro de este vasto campo reside el Aprendizaje Automático (ML), que se define no como una programación explícita de reglas, sino como el subcampo enfocado en sistemas que aprenden patrones directamente a partir de los datos. Finalmente, las Redes Neuronales se identifican como una subdisciplina específica del ML, inspirada en la arquitectura del cerebro biológico, que ha demostrado ser excepcionalmente eficaz en tareas complejas de reconocimiento de patrones.1\nUn pilar conceptual introducido tempranamente es el de los Modelos Paramétricos.1 Esta definición es crucial, ya que replantea el “aprendizaje” en un contexto matemático riguroso. Un modelo paramétrico es una función (como una red neuronal) cuya comportamiento está determinado por un conjunto de parámetros internos o “pesos”. En este contexto, el proceso de “aprendizaje” se define formalmente como un problema de optimización: el desafío de encontrar el conjunto óptimo de parámetros (pesos) que permita al modelo mapear entradas a salidas con la menor cantidad de error posible.\nEste encuadre inicial es fundamental. Al definir el aprendizaje automático como un problema de optimización de parámetros, el curso establece un hilo conductor que conecta lógicamente todos los temas subsecuentes. Si el objetivo es encontrar los mejores parámetros, y “mejor” se define como la minimización de una función de error, se deduce que todo el aprendizaje automático es, en esencia, un problema de optimización. Esta perspectiva prepara al estudiante para la introducción posterior y la importancia crítica de los algoritmos de optimización, como el Descenso por Gradiente.3\nB. El Entorno de Implementación (Python) Para traducir la teoría en práctica, el curso comienza con un módulo pragmático dedicado a la instalación y configuración del entorno de desarrollo.1 Esta base práctica es esencial, ya que el curso utiliza Python como lenguaje principal.1\nSe detalla la pila de software (el “stack”) que se ha convertido en el estándar de facto en la ciencia de datos y la investigación en IA 1:\nPython: El lenguaje de programación de alto nivel que sirve como la base de todo el curso.\nAnaconda: El gestor de entornos y paquetes, utilizado para aislar las dependencias del proyecto y asegurar la reproducibilidad.\nNumPy: La biblioteca fundamental para el cómputo numérico en Python.\nVS Code: El entorno de desarrollo integrado (IDE) para la edición de código.\nGit: El sistema de control de versiones distribuido para el seguimiento de los cambios en el código y los ejercicios.\nLa elección de NumPy no es una mera cuestión de conveniencia; es un requisito fundamental para el rendimiento. Las redes neuronales, como se demuestra en módulos posteriores del curso, son computacionalmente intensivas y se basan casi por completo en operaciones de álgebra lineal, como multiplicaciones de matrices y productos punto.4 Si bien Python es un lenguaje flexible, sus bucles nativos son notablemente lentos para estas operaciones matemáticas.\nNumPy resuelve este problema mediante la vectorización. Permite que operaciones complejas sobre grandes arreglos de datos (vectores y matrices) se ejecuten, no en el intérprete de Python, sino en código C compilado de bajo nivel, altamente optimizado. La insistencia del curso en configurar NumPy desde el segundo video 1 no es trivial; es la base que permite la implementación eficiente de los algoritmos de forward pass (predicción) y backward pass (entrenamiento) que se analizarán más adelante. Sin la computación vectorizada de NumPy, el entrenamiento de redes neuronales a cualquier escala sería computacionalmente inviable en Python.\nII. La Génesis de la Neurona Artificial: El Modelo McCulloch-Pitts (1943) A. Arquitectura del Modelo Antes de que las redes neuronales pudieran “aprender”, primero debían ser conceptualizadas como sistemas lógicos. El curso traza el origen de la neurona artificial hasta el influyente artículo de 1943 de Warren McCulloch (neurocientífico) y Walter Pitts (matemático).5 Su objetivo era profundamente ambicioso: tender un puente entre la fisiología (los impulsos eléctricos físicos en el cerebro) y la psicología (la generación del pensamiento).5\nEl modelo que propusieron, analizado en detalle 5, es una abstracción matemática de una neurona biológica. Sus componentes clave son definidos por su simplicidad y su naturaleza estrictamente lógica 5:\nEntradas (Inputs): Señales que recibe la neurona. Son estrictamente binarias (0 para “apagado” o 1 para “activo”). Crucialmente, las entradas se dividen en dos tipos: Excitatorias (E), que promueven la activación de la neurona, e Inhibitorias (I), que la suprimen.\nUmbral (Threshold, U): Un valor interno, definido como un número natural o positivo (incluyendo el cero), que debe ser superado para que la neurona se active.\nSalida (Output): El resultado de la neurona. Al igual que las entradas, es estrictamente binaria (0 o 1), simulando el comportamiento biológico de “todo o nada” (una neurona o se dispara, o no lo hace).\nPesos (Weights): El componente más definitorio del modelo McCulloch-Pitts es la ausencia de pesos sinápticos. Las entradas no están ponderadas; cada entrada activa contribuye con su valor binario (1) de manera uniforme.5\nB. Reglas de Activación y Capacidad Lógica El funcionamiento de la neurona de McCulloch-Pitts se rige por un proceso de activación en dos pasos, donde la inhibición tiene prioridad absoluta 5:\nRegla 1 (Verificación de Inhibición): La neurona primero comprueba si alguna de sus entradas Inhibitorias (I) está activa (es decir, tiene un valor de 1). Si esto ocurre, la neurona se apaga incondicionalmente y la Salida es 0. Las entradas excitatorias son irrelevantes en este caso.5\nRegla 2 (Evaluación de Excitación): Si, y solo si, la Regla 1 no se cumple (ninguna entrada inhibitoria está activa), la neurona procede a sumar todas sus entradas Excitatorias (E) activas.\nSi la $Suma_{Excitatoria} \\geq U$ (Umbral), la neurona se “dispara” y la Salida es 1.\nSi la $Suma_{Excitatoria} \u003c U$, la neurona permanece apagada y la Salida es 0.5\nEl curso demuestra que esta simple lógica permite al modelo de McCulloch-Pitts funcionar como las compuertas lógicas fundamentales de la computación booleana. Por ejemplo, una neurona con dos entradas excitatorias y un umbral $U=2$ funciona como una compuerta AND. Si el umbral es $U=1$, funciona como una compuerta OR. Una neurona con una entrada inhibitoria puede funcionar como una compuerta NOT.5\nC. La Limitación Fundamental La ausencia de pesos es, simultáneamente, la característica definitoria y la limitación fatal del modelo McCulloch-Pitts. Un modelo sin pesos es un modelo cuyos parámetros (la topología de entradas E/I y el valor del umbral U) son fijos. Para que el modelo ejecute una función lógica específica (como AND), un diseñador humano debe configurar manualmente estos parámetros.5\nDebido a que el modelo carece de un mecanismo para ajustar sus propios parámetros basándose en la experiencia o los datos, el modelo McCulloch-Pitts no puede aprender. Es una máquina lógica estática, no un sistema de aprendizaje automático. Esta incapacidad fundamental para adaptarse es la razón directa por la cual el campo necesitó evolucionar hacia el Perceptrón, un modelo que introduce el concepto revolucionario de pesos sinápticos modificables.\nElemento Infográfico (Tabla 1): Análisis Comparativo: McCulloch-Pitts vs. El Perceptrón III. El Perceptrón: El Amanecer del Aprendizaje Lineal A. La Evolución: Introducción de Pesos Sinápticos El curso identifica al Perceptrón, desarrollado por Frank Rosenblatt, como la siguiente etapa evolutiva crucial.1 Este modelo supera la limitación fundamental de McCulloch-Pitts al introducir el concepto de pesos sinápticos (w).\nA diferencia de su predecesor, el Perceptrón no trata todas las entradas por igual. A cada entrada $x_i$ se le asigna un peso $w_i$, que cuantifica la influencia (positiva o negativa) de esa entrada en la decisión final. La neurona ya no solo suma; calcula una suma ponderada, que es una combinación lineal de sus entradas ($ \\sum w_i x_i $). Este valor se compara luego con un umbral para producir una salida.\nEsta innovación es el nacimiento del aprendizaje automático en las redes neuronales. Los pesos no son fijos; son parámetros que pueden ser modificados o ajustados. El “aprendizaje” se convierte en el proceso algorítmico de encontrar los valores correctos para $w$ que permitan al Perceptrón clasificar correctamente sus entradas.\nB. El Rol de las Funciones de Activación La suma ponderada calculada por el Perceptrón se pasa a través de una función de activación para producir la salida final. El curso hace una distinción crítica entre dos tipos de estas funciones: lineales y no lineales.6\nUn Perceptrón simple (o incluso una red de Perceptrones apilados) que utiliza únicamente funciones de activación lineales (donde la salida es proporcional a la entrada, $y = cx$) está fundamentalmente limitado. Matemáticamente, apilar múltiples capas lineales es equivalente a una sola capa lineal, solo que con pesos diferentes. Como resultado, un Perceptrón lineal solo puede aprender y resolver problemas que son linealmente separables.6\nEsta es una limitación severa. Problemas del mundo real, e incluso problemas lógicos simples como el XOR (O exclusivo), no son linealmente separables. El curso utiliza esta limitación para establecer una de las reglas más importantes del aprendizaje profundo: la necesidad de la no linealidad. Para que las redes neuronales puedan aproximar funciones complejas y resolver problemas no lineales, deben incorporar funciones de activación no lineales, como la función Sigmoide ($ \\sigma(x) $) o la Unidad Lineal Rectificada (ReLU).1 Es esta combinación de múltiples capas (profundidad) y activaciones no lineales la que otorga a las redes neuronales modernas su poder expresivo.6\nIV. El Motor del Aprendizaje: Optimización mediante Descenso por Gradiente (GD) A. El Problema de la Optimización Una vez establecido que el aprendizaje consiste en ajustar los pesos (Sección III), la siguiente pregunta lógica es: ¿cómo se ajustan? El curso dedica una parte sustancial a explicar el Descenso por Gradiente (GD), el algoritmo de optimización que forma el núcleo del entrenamiento de casi todas las redes neuronales modernas.1\nEl propósito del GD es puramente la optimización.3 Su objetivo es encontrar el conjunto óptimo de pesos (denotado como $W^*$) que minimice una Función de Error (también llamada Función de Pérdida o Costo). Esta función, a menudo la “suma de cuadrados de los errores”, mide qué tan “equivocadas” están las predicciones de la red en comparación con los valores reales.3\nEl curso emplea una poderosa analogía para construir la intuición: la función de error se visualiza como un vasto paisaje montañoso, una “superficie de error”.3\nCada posible configuración de los pesos de la red ($W$) corresponde a una ubicación (coordenadas) en este paisaje.\nLa altitud en esa ubicación representa el error total de la red con esos pesos.3 Los picos altos tienen un error elevado; los valles profundos tienen un error bajo.\nEl entrenamiento comienza inicializando los pesos de forma aleatoria, lo que equivale a situarse en un punto arbitrario de esta montaña.3\n“Aprender”, por lo tanto, es el proceso de “bajar la montaña” 3, dando pasos iterativos para encontrar el punto más bajo posible: el mínimo global (o un mínimo local suficientemente bueno), donde el error de la red es el más bajo.3\nB. La Matemática del Gradiente El Descenso por Gradiente proporciona el método matemático para determinar en qué dirección dar cada paso para bajar la montaña. Utiliza el concepto de gradiente (denotado como $\\nabla$), que es un vector que contiene todas las derivadas parciales de la función de error (la altitud) con respecto a cada peso individual (las coordenadas).3\nMatemáticamente, el gradiente $\\nabla$ por definición siempre apunta en la dirección de máximo ascenso; es decir, indica el camino más rápido para subir la montaña.3\nEl insight central del algoritmo de Descenso por Gradiente es invertir esta información. Si el gradiente ($\\nabla$) apunta hacia dónde el error aumenta más rápido, el negativo del gradiente ($-\\nabla$) debe apuntar en la dirección opuesta, la dirección de máximo descenso.3 Este vector nos dice exactamente cómo modificar cada peso individual para reducir el error de la manera más eficiente.\nEsto conduce a la famosa “Regla de Actualización de Pesos”, que se aplica iterativamente:\n$W_{nuevo} = W_{anterior} - \\eta \\cdot \\nabla E(W_{anterior})$\nDonde:\n$W_{nuevo}$ son los pesos actualizados y con menor error.\n$W_{anterior}$ son los pesos del paso anterior.\n$\\nabla E(W)$ es el gradiente (calculado) del error con respecto a los pesos.\n$\\eta$ (eta) es la Tasa de Aprendizaje (Learning Rate). Este es un hiperparámetro crítico que controla el “tamaño del paso” que damos en la dirección del gradiente negativo.3 Una $\\eta$ demasiado grande puede hacer que “saltemos” por encima del mínimo, mientras que una $\\eta$ demasiado pequeña hará que el entrenamiento sea excesivamente lento.3\nC. Variantes del Descenso por Gradiente El cálculo del gradiente $\\nabla E(W)$ puede ser computacionalmente costoso. El curso analiza las tres variantes principales del GD, que se diferencian en la cantidad de datos que utilizan para estimar el gradiente en cada paso de actualización 7:\nBatch Gradient Descent (GD Batch): En esta variante, el gradiente se calcula utilizando todo el conjunto de datos de entrenamiento. Esto proporciona una estimación muy precisa y estable del gradiente (un camino suave hacia abajo), pero es computacionalmente prohibitivo para los grandes conjuntos de datos modernos.7\nStochastic Gradient Descent (SGD): En el extremo opuesto, el SGD calcula el gradiente y actualiza los pesos utilizando un solo ejemplo de datos a la vez. Es extremadamente rápido computacionalmente y su naturaleza “errática” o “ruidosa” (el camino es muy tembloroso) puede ayudar al modelo a escapar de mínimos locales.7\nMini-Batch Gradient Descent: Esta es la solución de compromiso y el método más utilizado en la práctica. El gradiente se calcula utilizando un pequeño subconjunto de datos (un “mini-batch”, ej. 32 o 64 ejemplos). Este enfoque equilibra la eficiencia computacional del SGD con la estabilidad de la estimación del gradiente del Batch GD.7\nElemento Infográfico (Tabla 2): El Algoritmo de Descenso por Gradiente (Pseudocódigo) V. El Algoritmo de Entrenamiento: Retropropagación (Backpropagation) en Profundidad A. El Problema del “Reparto de Culpa” (Credit Assignment) El Descenso por Gradiente (Sección IV) proporciona la regla de actualización ($W = W - \\eta \\cdot \\nabla E$), pero deja una pregunta abierta: ¿cómo calculamos eficientemente el gradiente $\\nabla E$, especialmente en una red profunda con millones de pesos?\nAquí es donde entra en juego el algoritmo de Retropropagación (Backpropagation).1 El curso lo presenta como la solución al “problema del reparto de culpa” (Credit Assignment Problem).8 En una red con múltiples capas, el error se calcula fácilmente en la capa de salida (la diferencia entre la predicción final y el valor real). Pero, ¿cómo sabemos cuánto contribuyó un peso individual en la primera capa oculta a ese error final?\nBackpropagation es el algoritmo que resuelve elegantemente este problema. Como su nombre indica, propaga eficientemente la señal de error hacia atrás, comenzando desde la capa de salida, atravesando las capas ocultas y llegando hasta la capa de entrada.8\nB. Backpropagation como la Regla de la Cadena Es fundamental entender la sinergia algorítmica que el curso establece. Backpropagation no es un algoritmo de optimización; ese es el rol del Descenso por Gradiente. Backpropagation es un algoritmo de cálculo de derivadas.8\nEspecíficamente, Backpropagation es la aplicación eficiente y recursiva de la Regla de la Cadena del cálculo diferencial. Permite calcular el gradiente de la función de error ($\\nabla E$) con respecto a cada peso individual en la red, sin importar cuán profundo se encuentre.\nEl entrenamiento moderno de redes neuronales, tal como se presenta en el curso, es una simbiosis de estos dos algoritmos:\nEl Descenso por Gradiente (Sección IV) es el optimizador. Dice: “Para minimizar el error, necesito el gradiente ($\\nabla E$)”. En una red simple, $\\nabla E$ es fácil de calcular. En una red profunda con millones de pesos, un cálculo ingenuo es computacionalmente intratable.\nLa Retropropagación (Sección V) es el calculador. Dice: “Aquí tienes un método rápido y eficiente (usando la Regla de la Cadena y la programación dinámica) para calcular ese $\\nabla E$ para todos los millones de pesos”.8\nJuntos, forman el ciclo de entrenamiento: en cada iteración, se realiza un pase hacia adelante (predicción), se calcula el error, Backpropagation calcula el gradiente del error hacia atrás, y el Descenso por Gradiente utiliza ese gradiente para actualizar los pesos hacia adelante.\nVI. Arquitecturas de Múltiples Capas: El Perceptrón Multicapa (MLP) y su Implementación A. La Solución a la No Linealidad Armado con un optimizador (GD) y un calculador de gradiente (Backpropagation), el curso regresa a la arquitectura que resuelve la limitación de linealidad del Perceptrón simple: el Perceptrón Multicapa (MLP).1\nComo se estableció en la Sección III, la limitación del Perceptrón simple (como la incapacidad de resolver el XOR) se supera mediante la combinación de dos elementos arquitectónicos clave que definen al MLP:\nLa inclusión de una o más capas ocultas (capas de neuronas entre la entrada y la salida).\nEl uso de funciones de activación no lineales (como la Sigmoide) en las neuronas de estas capas ocultas.4\nEsta combinación permite al MLP “doblar” y “retorcer” el espacio de características, creando regiones de decisión no lineales complejas, permitiéndole así aproximar cualquier función continua.\nB. Implementación del Forward Pass El curso incluye un video crucial que implementa un MLP desde cero usando Python y NumPy.4 Este ejercicio didáctico se centra en el pase hacia adelante (forward pass), que es el proceso que utiliza la red para generar una predicción a partir de una entrada.4\nEl análisis de esta implementación revela los siguientes pasos 4:\nDefinir la Estructura: Se especifica la arquitectura. En el ejemplo del video, se usa una red de 4 nodos de entrada, 3 nodos en la capa oculta y 2 nodos de salida (una arquitectura 4-3-2).4\nInicializar las Matrices de Pesos: Los pesos se inicializan aleatoriamente (a menudo usando una distribución normal con media 0) y se almacenan en matrices de NumPy.4\nMatriz $W_1$ (Input a Hidden): Dimensiones 4x3.\nMatriz $W_2$ (Hidden a Output): Dimensiones 3x2.\nDefinir la Entrada: Se crea un vector de entrada $X$ (ej. un vector 1x4).4\nCalcular la Salida de la Capa Oculta ($H$):\nSe calcula la suma ponderada mediante el producto punto matricial: $Z_1 = X \\cdot W_1$.4\nSe aplica la función de activación no lineal (Sigmoide): $H = \\sigma(Z_1)$.4\nCalcular la Salida Final ($Y$): Se calcula la siguiente suma ponderada usando la salida de la capa anterior: $Z_2 = H \\cdot W_2$.4\nSe aplica la activación final para obtener la predicción: $Y = \\sigma(Z_2)$.4\nC. Distinción Crítica: Implementación vs. Entrenamiento El análisis de este video de implementación 4 revela una decisión pedagógica deliberada y crucial. El video se enfoca exclusivamente en el forward pass (cómo la arquitectura genera una salida). Explícitamente, no implementa el algoritmo de Backpropagation ni la actualización de pesos del Descenso por Gradiente.4\nEsto es fundamental para el estudiante: el curso separa la arquitectura (el flujo de información hacia adelante para la predicción) del entrenamiento (el flujo de error hacia atrás para el aprendizaje). La implementación 4 muestra cómo se construye y ejecuta un MLP. El entrenamiento real requeriría tomar este código y combinarlo con los algoritmos de las Secciones IV (GD) y V (Backpropagation) para calcular el gradiente del error y actualizar iterativamente las matrices $W_1$ y $W_2$.\nVII. Arquitecturas Avanzadas: Introducción a las Redes Neuronales Convolucionales (CNN) A. El Desafío de los Datos Multidimensionales La sección final del curso aborda una de las arquitecturas de aprendizaje profundo más influyentes: las Redes Neuronal Convolucionales (CNN).1\nEl curso motiva la necesidad de las CNN al exponer las fallas del MLP (Sección VI) cuando se enfrenta a datos de alta dimensionalidad con estructura espacial, como las imágenes.10 Si se quisiera alimentar una imagen modesta de 1000x1000 píxeles a un MLP, primero se debería “aplanar” en un vector de 1,000,000 de entradas. La primera capa oculta tendría miles de millones de pesos, creando una explosión de parámetros. Peor aún, este aplanamiento destruye toda la información espacial: la red ya no sabe qué píxeles estaban uno al lado del otro.\nLas CNN están diseñadas específicamente para superar estos dos problemas, preservando la información espacial y siendo computacionalmente eficientes.\nB. Los Componentes Arquitectónicos Clave de una CNN Las CNN introducen dos nuevos tipos de capas fundamentales que actúan como un potente extractor de características, analizadas en detalle en el video 10:\nLa Capa de Convolución 10: Kernel (o Filtro/Template): En lugar de neuronas totalmente conectadas, esta capa utiliza un kernel, que es una pequeña matriz de pesos (ej. 3x3 o 5x5). Este kernel está diseñado para detectar una característica local específica, como un borde vertical, una esquina o la curva de un ojo.10\nProceso de Convolución: El proceso (técnicamente una correlación cruzada) consiste en deslizar este mismo kernel por toda la imagen de entrada. En cada posición, se realiza una multiplicación elemento a elemento entre el kernel y el parche de la imagen, y los resultados se suman.10\nMapa de Características (Feature Map): La salida de esta operación. Es un nuevo “mapa” 2D que indica dónde se detectó la característica. Las áreas con valores altos (“brillantes”) en el mapa de características son donde el kernel encontró una coincidencia fuerte.10 Una capa de convolución aprende múltiples kernels en paralelo, buscando múltiples características a la vez.\nLa Capa de Agrupación (Pooling) 10: Max Pooling: Esta es la variante más común.10 Desliza una pequeña ventana (ej. 2x2) sobre el mapa de características y, para cada ventana, selecciona únicamente el valor máximo, descartando los demás.10\nPropósito: Esta operación reduce drásticamente las dimensiones (ancho y alto) del mapa de características, un proceso llamado downsampling. Esto tiene dos beneficios: reduce la complejidad computacional para las capas siguientes y hace que la representación sea más robusta al ruido, reteniendo solo la señal más fuerte de la característica detectada.10\nC. Principios Fundamentales de las CNN La arquitectura de las CNN se basa en principios que las hacen ideales para la visión por computadora 10:\nInvarianza de Posición: Este es el objetivo central. Al aplicar el mismo kernel en toda la imagen, la red aprende a detectar una característica (como un ojo) sin importar dónde aparece en la imagen (arriba, abajo, izquierda o derecha).10 Un MLP tendría que aprender esa característica de nuevo en cada posición posible.\nCompartición de Parámetros (Parameter Sharing): Este es el “truco” que dota a las CNN de su eficiencia. En lugar de aprender un peso único para cada píxel (como un MLP), la CNN aprende solo los pesos dentro del kernel (ej. 9 pesos en un kernel de 3x3). Esos mismos 9 pesos se comparten (reutilizan) en cada posición de la imagen. Esto reduce drásticamente el número total de parámetros a aprender, haciendo el entrenamiento más rápido y reduciendo el sobreajuste.\nArquitectura Híbrida: Una CNN completa es una arquitectura híbrida. La primera parte de la red (el extractor de características) consiste en una pila de capas de Convolución y Pooling. Estas capas toman la imagen 2D bruta y la transforman progresivamente en un conjunto de mapas de características pequeños y abstractos. La salida de esta pila finalmente se “aplana” en un vector largo, que luego se alimenta a un MLP estándar (como el de la Sección VI) que actúa como el clasificador final.10 En esencia, la CNN aprende automáticamente a extraer las características relevantes, liberando al MLP de tener que hacerlo desde datos de píxeles brutos.\nElemento Infográfico (Tabla 3): Anatomía de una Red Neuronal Convolucional (CNN) VIII. Síntesis y Conclusión del Curso El curso intensivo de redes neuronales de Irving Vasquez 1 proporciona una trayectoria de aprendizaje coherente y rigurosa, guiando al estudiante desde los fundamentos filosóficos de la IA hasta las arquitecturas modernas de aprendizaje profundo.\nLa síntesis del curso revela una narrativa lógica:\nComienza con la neurona lógica estática (McCulloch-Pitts), que puede modelar la lógica pero no puede aprender.5\nLa limitación del no-aprendizaje se supera con el Perceptrón y sus pesos modificables.1\nLa limitación del Perceptrón (linealidad) se supera con el MLP y sus activaciones no lineales.6\nEl problema de cómo entrenar un MLP se define como un problema de optimización, resuelto por el Descenso por Gradiente.3\nEl desafío computacional del Descenso por Gradiente (el cálculo de $\\nabla E$) se resuelve con el algoritmo de Backpropagation.8\nFinalmente, la limitación del MLP (datos de alta dimensionalidad como imágenes) se supera con la arquitectura especializada de las CNN.10\nComo se indica en la presentación del curso, esta lista de reproducción de 25 videos sirve como un pilar fundamental. Al cubrir la teoría matemática (GD, Backpropagation) y la implementación práctica (Python, NumPy, MLP, CNN), el curso proporciona la base indispensable sobre la cual se construyen todos los temas avanzados del Deep Learning.11 El estudiante que completa este currículo no solo sabe cómo usar las redes neuronales, sino que entiende por qué y cómo funcionan a nivel fundamental.\nFuentes citadas Introducción a las redes neuronales - YouTube, acceso: octubre 24, 2025, https://youtube.com/playlist?list=PLVo0_3_ZKpuBeGJQneleWT0vg4aPqTveF\nInteligencia artificial y redes neuronales - YouTube, acceso: octubre 24, 2025, https://www.youtube.com/watch?v=wZh3ReAxAaU\nDescenso por gradiente explicado a detalle - YouTube, acceso: octubre 24, 2025, https://www.youtube.com/watch?v=cwkGzEXUuMs\nImplementación de la red neuronal multicapa (MLP) en Python - YouTube, acceso: octubre 24, 2025, https://www.youtube.com/watch?v=kp1K0QaY9kY\nModelo McCulloch y Pitts: La primer neurona artificial - YouTube, acceso: octubre 24, 2025, https://www.youtube.com/watch?v=JaLMcVO1CCE\n¿Cuál es la capacidad de una red neuronal? - YouTube, acceso: octubre 24, 2025, https://www.youtube.com/watch?v=JCA2DDOkweE\nEl Perceptrón - Descenso por Gradiente - YouTube, acceso: octubre 24, 2025, https://www.youtube.com/watch?v=ytzyN1v7-6M\nBackpropagation (Retropropagación) - YouTube, acceso: octubre 24, 2025, https://www.youtube.com/watch?v=bJFM9rvpwaY\nAlgoritmo Backpropagation - YouTube, acceso: octubre 24, 2025, https://www.youtube.com/watch?v=CdkgZJS5Caw\nRedes neuronales convolucionales a detalle - YouTube, acceso: octubre 24, 2025, https://www.youtube.com/watch?v=Xk2HdJQjdyc\nIntroducción a las redes neuronales - Presentación del curso - YouTube, acceso: octubre 24, 2025, https://www.youtube.com/watch?v=cF0cqcw_LSw\n","wordCount":"4268","inLanguage":"en","datePublished":"2025-10-24T22:18:56Z","dateModified":"2025-10-24T22:18:56Z","author":{"@type":"Person","name":"Ancordss"},"mainEntityOfPage":{"@type":"WebPage","@id":"https://ancordss.github.io/post/ia/"},"publisher":{"@type":"Organization","name":"Ancordss-Blog!","logo":{"@type":"ImageObject","url":"https://ancordss.github.io/favicon.ico"}}}</script></head><body id=top><script>localStorage.getItem("pref-theme")==="dark"?document.body.classList.add("dark"):localStorage.getItem("pref-theme")==="light"?document.body.classList.remove("dark"):window.matchMedia("(prefers-color-scheme: dark)").matches&&document.body.classList.add("dark")</script><header class=header><nav class=nav><div class=logo><a href=https://ancordss.github.io/ accesskey=h title="Ancordss-Blog! (Alt + H)"><img src=https://ancordss.github.io/apple-touch-icon.png alt=logo aria-label=logo height=35>Ancordss-Blog!</a>
<span class=logo-switches><button id=theme-toggle accesskey=t title="(Alt + T)"><svg id="moon" xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg><svg id="sun" xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg></button><ul class=lang-switch><li>|</li></ul></span></div><ul id=menu><li><a href=https://ancordss.github.io/categories/ title=Categories><span>Categories</span></a></li><li><a href=https://ancordss.github.io/tags/ title=Tags><span>Tags</span></a></li></ul></nav></header><main class=main><article class=post-single><header class=post-header><div class=breadcrumbs><a href=https://ancordss.github.io/>Home</a>&nbsp;»&nbsp;<a href=https://ancordss.github.io/post/>Posts</a></div><h1 class=post-title>Infografia Redes Neuronales</h1><div class=post-meta>&lt;span title='2025-10-24 22:18:56 +0000 UTC'>October 24, 2025&lt;/span>&amp;nbsp;·&amp;nbsp;21 min&amp;nbsp;·&amp;nbsp;Ancordss&nbsp;|&nbsp;<a href=https://github.com/Ancordss/Ancordss.github.io/tree/main/content/post/ia.md rel="noopener noreferrer" target=_blank>Suggest Changes</a></div></header><div class=post-content><h2 id=i-introducción-el-ecosistema-de-la-inteligencia-artificial-y-la-configuración-del-entorno-práctico>I. Introducción: El Ecosistema de la Inteligencia Artificial y la Configuración del Entorno Práctico<a hidden class=anchor aria-hidden=true href=#i-introducción-el-ecosistema-de-la-inteligencia-artificial-y-la-configuración-del-entorno-práctico>#</a></h2><h3 id=a-contextualización-y-definiciones-fundamentales>A. Contextualización y Definiciones Fundamentales<a hidden class=anchor aria-hidden=true href=#a-contextualización-y-definiciones-fundamentales>#</a></h3><p>El &ldquo;Curso intensivo de redes neuronales&rdquo; impartido por Irving Vasquez 1 constituye una exploración estructurada de los fundamentos teóricos y prácticos que sustentan el campo moderno de la inteligencia artificial. Para navegar este dominio, el curso establece, en primer lugar, una jerarquía conceptual precisa, distinguiendo entre los términos que a menudo se usan indistintamente.2</p><p>La Inteligencia Artificial (IA) se presenta como el campo más amplio, una disciplina de la informática dedicada a crear sistemas que pueden simular tareas que normalmente requieren inteligencia humana. Dentro de este vasto campo reside el Aprendizaje Automático (ML), que se define no como una programación explícita de reglas, sino como el subcampo enfocado en sistemas que aprenden patrones directamente a partir de los datos. Finalmente, las Redes Neuronales se identifican como una subdisciplina específica del ML, inspirada en la arquitectura del cerebro biológico, que ha demostrado ser excepcionalmente eficaz en tareas complejas de reconocimiento de patrones.1</p><p>Un pilar conceptual introducido tempranamente es el de los Modelos Paramétricos.1 Esta definición es crucial, ya que replantea el &ldquo;aprendizaje&rdquo; en un contexto matemático riguroso. Un modelo paramétrico es una función (como una red neuronal) cuya comportamiento está determinado por un conjunto de parámetros internos o &ldquo;pesos&rdquo;. En este contexto, el proceso de &ldquo;aprendizaje&rdquo; se define formalmente como un problema de optimización: el desafío de encontrar el conjunto óptimo de parámetros (pesos) que permita al modelo mapear entradas a salidas con la menor cantidad de error posible.</p><p>Este encuadre inicial es fundamental. Al definir el aprendizaje automático como un problema de optimización de parámetros, el curso establece un hilo conductor que conecta lógicamente todos los temas subsecuentes. Si el objetivo es encontrar los mejores parámetros, y &ldquo;mejor&rdquo; se define como la minimización de una función de error, se deduce que todo el aprendizaje automático es, en esencia, un problema de optimización. Esta perspectiva prepara al estudiante para la introducción posterior y la importancia crítica de los algoritmos de optimización, como el Descenso por Gradiente.3</p><h3 id=b-el-entorno-de-implementación-python>B. El Entorno de Implementación (Python)<a hidden class=anchor aria-hidden=true href=#b-el-entorno-de-implementación-python>#</a></h3><p>Para traducir la teoría en práctica, el curso comienza con un módulo pragmático dedicado a la instalación y configuración del entorno de desarrollo.1 Esta base práctica es esencial, ya que el curso utiliza Python como lenguaje principal.1</p><p>Se detalla la pila de software (el &ldquo;stack&rdquo;) que se ha convertido en el estándar de facto en la ciencia de datos y la investigación en IA 1:</p><ul><li><p>Python: El lenguaje de programación de alto nivel que sirve como la base de todo el curso.</p></li><li><p>Anaconda: El gestor de entornos y paquetes, utilizado para aislar las dependencias del proyecto y asegurar la reproducibilidad.</p></li><li><p>NumPy: La biblioteca fundamental para el cómputo numérico en Python.</p></li><li><p>VS Code: El entorno de desarrollo integrado (IDE) para la edición de código.</p></li><li><p>Git: El sistema de control de versiones distribuido para el seguimiento de los cambios en el código y los ejercicios.</p></li></ul><p>La elección de NumPy no es una mera cuestión de conveniencia; es un requisito fundamental para el rendimiento. Las redes neuronales, como se demuestra en módulos posteriores del curso, son computacionalmente intensivas y se basan casi por completo en operaciones de álgebra lineal, como multiplicaciones de matrices y productos punto.4 Si bien Python es un lenguaje flexible, sus bucles nativos son notablemente lentos para estas operaciones matemáticas.</p><p>NumPy resuelve este problema mediante la vectorización. Permite que operaciones complejas sobre grandes arreglos de datos (vectores y matrices) se ejecuten, no en el intérprete de Python, sino en código C compilado de bajo nivel, altamente optimizado. La insistencia del curso en configurar NumPy desde el segundo video 1 no es trivial; es la base que permite la implementación eficiente de los algoritmos de forward pass (predicción) y backward pass (entrenamiento) que se analizarán más adelante. Sin la computación vectorizada de NumPy, el entrenamiento de redes neuronales a cualquier escala sería computacionalmente inviable en Python.</p><h2 id=ii-la-génesis-de-la-neurona-artificial-el-modelo-mcculloch-pitts-1943>II. La Génesis de la Neurona Artificial: El Modelo McCulloch-Pitts (1943)<a hidden class=anchor aria-hidden=true href=#ii-la-génesis-de-la-neurona-artificial-el-modelo-mcculloch-pitts-1943>#</a></h2><h3 id=a-arquitectura-del-modelo>A. Arquitectura del Modelo<a hidden class=anchor aria-hidden=true href=#a-arquitectura-del-modelo>#</a></h3><p>Antes de que las redes neuronales pudieran &ldquo;aprender&rdquo;, primero debían ser conceptualizadas como sistemas lógicos. El curso traza el origen de la neurona artificial hasta el influyente artículo de 1943 de Warren McCulloch (neurocientífico) y Walter Pitts (matemático).5 Su objetivo era profundamente ambicioso: tender un puente entre la fisiología (los impulsos eléctricos físicos en el cerebro) y la psicología (la generación del pensamiento).5</p><p>El modelo que propusieron, analizado en detalle 5, es una abstracción matemática de una neurona biológica. Sus componentes clave son definidos por su simplicidad y su naturaleza estrictamente lógica 5:</p><ol><li><p>Entradas (Inputs): Señales que recibe la neurona. Son estrictamente binarias (0 para &ldquo;apagado&rdquo; o 1 para &ldquo;activo&rdquo;). Crucialmente, las entradas se dividen en dos tipos: Excitatorias (E), que promueven la activación de la neurona, e Inhibitorias (I), que la suprimen.</p></li><li><p>Umbral (Threshold, U): Un valor interno, definido como un número natural o positivo (incluyendo el cero), que debe ser superado para que la neurona se active.</p></li><li><p>Salida (Output): El resultado de la neurona. Al igual que las entradas, es estrictamente binaria (0 o 1), simulando el comportamiento biológico de &ldquo;todo o nada&rdquo; (una neurona o se dispara, o no lo hace).</p></li><li><p>Pesos (Weights): El componente más definitorio del modelo McCulloch-Pitts es la ausencia de pesos sinápticos. Las entradas no están ponderadas; cada entrada activa contribuye con su valor binario (1) de manera uniforme.5</p></li></ol><h3 id=b-reglas-de-activación-y-capacidad-lógica>B. Reglas de Activación y Capacidad Lógica<a hidden class=anchor aria-hidden=true href=#b-reglas-de-activación-y-capacidad-lógica>#</a></h3><p>El funcionamiento de la neurona de McCulloch-Pitts se rige por un proceso de activación en dos pasos, donde la inhibición tiene prioridad absoluta 5:</p><ol><li><p>Regla 1 (Verificación de Inhibición): La neurona primero comprueba si alguna de sus entradas Inhibitorias (I) está activa (es decir, tiene un valor de 1). Si esto ocurre, la neurona se apaga incondicionalmente y la Salida es 0. Las entradas excitatorias son irrelevantes en este caso.5</p></li><li><p>Regla 2 (Evaluación de Excitación): Si, y solo si, la Regla 1 no se cumple (ninguna entrada inhibitoria está activa), la neurona procede a sumar todas sus entradas Excitatorias (E) activas.</p></li></ol><ul><li><p>Si la $Suma_{Excitatoria} \geq U$ (Umbral), la neurona se &ldquo;dispara&rdquo; y la Salida es 1.</p></li><li><p>Si la $Suma_{Excitatoria} &lt; U$, la neurona permanece apagada y la Salida es 0.5</p></li></ul><p>El curso demuestra que esta simple lógica permite al modelo de McCulloch-Pitts funcionar como las compuertas lógicas fundamentales de la computación booleana. Por ejemplo, una neurona con dos entradas excitatorias y un umbral $U=2$ funciona como una compuerta AND. Si el umbral es $U=1$, funciona como una compuerta OR. Una neurona con una entrada inhibitoria puede funcionar como una compuerta NOT.5</p><h3 id=c-la-limitación-fundamental>C. La Limitación Fundamental<a hidden class=anchor aria-hidden=true href=#c-la-limitación-fundamental>#</a></h3><p>La ausencia de pesos es, simultáneamente, la característica definitoria y la limitación fatal del modelo McCulloch-Pitts. Un modelo sin pesos es un modelo cuyos parámetros (la topología de entradas E/I y el valor del umbral U) son fijos. Para que el modelo ejecute una función lógica específica (como AND), un diseñador humano debe configurar manualmente estos parámetros.5</p><p>Debido a que el modelo carece de un mecanismo para ajustar sus propios parámetros basándose en la experiencia o los datos, el modelo McCulloch-Pitts no puede aprender. Es una máquina lógica estática, no un sistema de aprendizaje automático. Esta incapacidad fundamental para adaptarse es la razón directa por la cual el campo necesitó evolucionar hacia el Perceptrón, un modelo que introduce el concepto revolucionario de pesos sinápticos modificables.</p><h3 id=elemento-infográfico-tabla-1-análisis-comparativo-mcculloch-pitts-vs-el-perceptrón>Elemento Infográfico (Tabla 1): Análisis Comparativo: McCulloch-Pitts vs. El Perceptrón<a hidden class=anchor aria-hidden=true href=#elemento-infográfico-tabla-1-análisis-comparativo-mcculloch-pitts-vs-el-perceptrón>#</a></h3><p><img loading=lazy src="https://github.com/Ancordss/Ancordss.github.io/blob/main/static/info/image.png?raw=true" alt="tabla 1"></p><h2 id=iii-el-perceptrón-el-amanecer-del-aprendizaje-lineal>III. El Perceptrón: El Amanecer del Aprendizaje Lineal<a hidden class=anchor aria-hidden=true href=#iii-el-perceptrón-el-amanecer-del-aprendizaje-lineal>#</a></h2><h3 id=a-la-evolución-introducción-de-pesos-sinápticos>A. La Evolución: Introducción de Pesos Sinápticos<a hidden class=anchor aria-hidden=true href=#a-la-evolución-introducción-de-pesos-sinápticos>#</a></h3><p>El curso identifica al Perceptrón, desarrollado por Frank Rosenblatt, como la siguiente etapa evolutiva crucial.1 Este modelo supera la limitación fundamental de McCulloch-Pitts al introducir el concepto de pesos sinápticos (w).</p><p>A diferencia de su predecesor, el Perceptrón no trata todas las entradas por igual. A cada entrada $x_i$ se le asigna un peso $w_i$, que cuantifica la influencia (positiva o negativa) de esa entrada en la decisión final. La neurona ya no solo suma; calcula una suma ponderada, que es una combinación lineal de sus entradas ($ \sum w_i x_i $). Este valor se compara luego con un umbral para producir una salida.</p><p>Esta innovación es el nacimiento del aprendizaje automático en las redes neuronales. Los pesos no son fijos; son parámetros que pueden ser modificados o ajustados. El &ldquo;aprendizaje&rdquo; se convierte en el proceso algorítmico de encontrar los valores correctos para $w$ que permitan al Perceptrón clasificar correctamente sus entradas.</p><h3 id=b-el-rol-de-las-funciones-de-activación>B. El Rol de las Funciones de Activación<a hidden class=anchor aria-hidden=true href=#b-el-rol-de-las-funciones-de-activación>#</a></h3><p>La suma ponderada calculada por el Perceptrón se pasa a través de una función de activación para producir la salida final. El curso hace una distinción crítica entre dos tipos de estas funciones: lineales y no lineales.6</p><p>Un Perceptrón simple (o incluso una red de Perceptrones apilados) que utiliza únicamente funciones de activación lineales (donde la salida es proporcional a la entrada, $y = cx$) está fundamentalmente limitado. Matemáticamente, apilar múltiples capas lineales es equivalente a una sola capa lineal, solo que con pesos diferentes. Como resultado, un Perceptrón lineal solo puede aprender y resolver problemas que son linealmente separables.6</p><p>Esta es una limitación severa. Problemas del mundo real, e incluso problemas lógicos simples como el XOR (O exclusivo), no son linealmente separables. El curso utiliza esta limitación para establecer una de las reglas más importantes del aprendizaje profundo: la necesidad de la no linealidad. Para que las redes neuronales puedan aproximar funciones complejas y resolver problemas no lineales, deben incorporar funciones de activación no lineales, como la función Sigmoide ($ \sigma(x) $) o la Unidad Lineal Rectificada (ReLU).1 Es esta combinación de múltiples capas (profundidad) y activaciones no lineales la que otorga a las redes neuronales modernas su poder expresivo.6</p><h2 id=iv-el-motor-del-aprendizaje-optimización-mediante-descenso-por-gradiente-gd>IV. El Motor del Aprendizaje: Optimización mediante Descenso por Gradiente (GD)<a hidden class=anchor aria-hidden=true href=#iv-el-motor-del-aprendizaje-optimización-mediante-descenso-por-gradiente-gd>#</a></h2><h3 id=a-el-problema-de-la-optimización>A. El Problema de la Optimización<a hidden class=anchor aria-hidden=true href=#a-el-problema-de-la-optimización>#</a></h3><p>Una vez establecido que el aprendizaje consiste en ajustar los pesos (Sección III), la siguiente pregunta lógica es: ¿cómo se ajustan? El curso dedica una parte sustancial a explicar el Descenso por Gradiente (GD), el algoritmo de optimización que forma el núcleo del entrenamiento de casi todas las redes neuronales modernas.1</p><p>El propósito del GD es puramente la optimización.3 Su objetivo es encontrar el conjunto óptimo de pesos (denotado como $W^*$) que minimice una Función de Error (también llamada Función de Pérdida o Costo). Esta función, a menudo la &ldquo;suma de cuadrados de los errores&rdquo;, mide qué tan &ldquo;equivocadas&rdquo; están las predicciones de la red en comparación con los valores reales.3</p><p>El curso emplea una poderosa analogía para construir la intuición: la función de error se visualiza como un vasto paisaje montañoso, una &ldquo;superficie de error&rdquo;.3</p><ol><li><p>Cada posible configuración de los pesos de la red ($W$) corresponde a una ubicación (coordenadas) en este paisaje.</p></li><li><p>La altitud en esa ubicación representa el error total de la red con esos pesos.3 Los picos altos tienen un error elevado; los valles profundos tienen un error bajo.</p></li><li><p>El entrenamiento comienza inicializando los pesos de forma aleatoria, lo que equivale a situarse en un punto arbitrario de esta montaña.3</p></li><li><p>&ldquo;Aprender&rdquo;, por lo tanto, es el proceso de &ldquo;bajar la montaña&rdquo; 3, dando pasos iterativos para encontrar el punto más bajo posible: el mínimo global (o un mínimo local suficientemente bueno), donde el error de la red es el más bajo.3</p></li></ol><h3 id=b-la-matemática-del-gradiente>B. La Matemática del Gradiente<a hidden class=anchor aria-hidden=true href=#b-la-matemática-del-gradiente>#</a></h3><p>El Descenso por Gradiente proporciona el método matemático para determinar en qué dirección dar cada paso para bajar la montaña. Utiliza el concepto de gradiente (denotado como $\nabla$), que es un vector que contiene todas las derivadas parciales de la función de error (la altitud) con respecto a cada peso individual (las coordenadas).3</p><p>Matemáticamente, el gradiente $\nabla$ por definición siempre apunta en la dirección de máximo ascenso; es decir, indica el camino más rápido para subir la montaña.3</p><p>El insight central del algoritmo de Descenso por Gradiente es invertir esta información. Si el gradiente ($\nabla$) apunta hacia dónde el error aumenta más rápido, el negativo del gradiente ($-\nabla$) debe apuntar en la dirección opuesta, la dirección de máximo descenso.3 Este vector nos dice exactamente cómo modificar cada peso individual para reducir el error de la manera más eficiente.</p><p>Esto conduce a la famosa &ldquo;Regla de Actualización de Pesos&rdquo;, que se aplica iterativamente:</p><p>$W_{nuevo} = W_{anterior} - \eta \cdot \nabla E(W_{anterior})$</p><p>Donde:</p><ul><li><p>$W_{nuevo}$ son los pesos actualizados y con menor error.</p></li><li><p>$W_{anterior}$ son los pesos del paso anterior.</p></li><li><p>$\nabla E(W)$ es el gradiente (calculado) del error con respecto a los pesos.</p></li><li><p>$\eta$ (eta) es la Tasa de Aprendizaje (Learning Rate). Este es un hiperparámetro crítico que controla el &ldquo;tamaño del paso&rdquo; que damos en la dirección del gradiente negativo.3 Una $\eta$ demasiado grande puede hacer que &ldquo;saltemos&rdquo; por encima del mínimo, mientras que una $\eta$ demasiado pequeña hará que el entrenamiento sea excesivamente lento.3</p></li></ul><h3 id=c-variantes-del-descenso-por-gradiente>C. Variantes del Descenso por Gradiente<a hidden class=anchor aria-hidden=true href=#c-variantes-del-descenso-por-gradiente>#</a></h3><p>El cálculo del gradiente $\nabla E(W)$ puede ser computacionalmente costoso. El curso analiza las tres variantes principales del GD, que se diferencian en la cantidad de datos que utilizan para estimar el gradiente en cada paso de actualización 7:</p><ol><li><p>Batch Gradient Descent (GD Batch): En esta variante, el gradiente se calcula utilizando todo el conjunto de datos de entrenamiento. Esto proporciona una estimación muy precisa y estable del gradiente (un camino suave hacia abajo), pero es computacionalmente prohibitivo para los grandes conjuntos de datos modernos.7</p></li><li><p>Stochastic Gradient Descent (SGD): En el extremo opuesto, el SGD calcula el gradiente y actualiza los pesos utilizando un solo ejemplo de datos a la vez. Es extremadamente rápido computacionalmente y su naturaleza &ldquo;errática&rdquo; o &ldquo;ruidosa&rdquo; (el camino es muy tembloroso) puede ayudar al modelo a escapar de mínimos locales.7</p></li><li><p>Mini-Batch Gradient Descent: Esta es la solución de compromiso y el método más utilizado en la práctica. El gradiente se calcula utilizando un pequeño subconjunto de datos (un &ldquo;mini-batch&rdquo;, ej. 32 o 64 ejemplos). Este enfoque equilibra la eficiencia computacional del SGD con la estabilidad de la estimación del gradiente del Batch GD.7</p></li></ol><h3 id=elemento-infográfico-tabla-2-el-algoritmo-de-descenso-por-gradiente-pseudocódigo>Elemento Infográfico (Tabla 2): El Algoritmo de Descenso por Gradiente (Pseudocódigo)<a hidden class=anchor aria-hidden=true href=#elemento-infográfico-tabla-2-el-algoritmo-de-descenso-por-gradiente-pseudocódigo>#</a></h3><p><img loading=lazy src="https://github.com/Ancordss/Ancordss.github.io/blob/main/static/info/image-1.png?raw=true" alt="tabla 2"></p><h2 id=v-el-algoritmo-de-entrenamiento-retropropagación-backpropagation-en-profundidad>V. El Algoritmo de Entrenamiento: Retropropagación (Backpropagation) en Profundidad<a hidden class=anchor aria-hidden=true href=#v-el-algoritmo-de-entrenamiento-retropropagación-backpropagation-en-profundidad>#</a></h2><h3 id=a-el-problema-del-reparto-de-culpa-credit-assignment>A. El Problema del &ldquo;Reparto de Culpa&rdquo; (Credit Assignment)<a hidden class=anchor aria-hidden=true href=#a-el-problema-del-reparto-de-culpa-credit-assignment>#</a></h3><p>El Descenso por Gradiente (Sección IV) proporciona la regla de actualización ($W = W - \eta \cdot \nabla E$), pero deja una pregunta abierta: ¿cómo calculamos eficientemente el gradiente $\nabla E$, especialmente en una red profunda con millones de pesos?</p><p>Aquí es donde entra en juego el algoritmo de Retropropagación (Backpropagation).1 El curso lo presenta como la solución al &ldquo;problema del reparto de culpa&rdquo; (Credit Assignment Problem).8 En una red con múltiples capas, el error se calcula fácilmente en la capa de salida (la diferencia entre la predicción final y el valor real). Pero, ¿cómo sabemos cuánto contribuyó un peso individual en la primera capa oculta a ese error final?</p><p>Backpropagation es el algoritmo que resuelve elegantemente este problema. Como su nombre indica, propaga eficientemente la señal de error hacia atrás, comenzando desde la capa de salida, atravesando las capas ocultas y llegando hasta la capa de entrada.8</p><h3 id=b-backpropagation-como-la-regla-de-la-cadena>B. Backpropagation como la Regla de la Cadena<a hidden class=anchor aria-hidden=true href=#b-backpropagation-como-la-regla-de-la-cadena>#</a></h3><p>Es fundamental entender la sinergia algorítmica que el curso establece. Backpropagation no es un algoritmo de optimización; ese es el rol del Descenso por Gradiente. Backpropagation es un algoritmo de cálculo de derivadas.8</p><p>Específicamente, Backpropagation es la aplicación eficiente y recursiva de la Regla de la Cadena del cálculo diferencial. Permite calcular el gradiente de la función de error ($\nabla E$) con respecto a cada peso individual en la red, sin importar cuán profundo se encuentre.</p><p>El entrenamiento moderno de redes neuronales, tal como se presenta en el curso, es una simbiosis de estos dos algoritmos:</p><ol><li><p>El Descenso por Gradiente (Sección IV) es el optimizador. Dice: &ldquo;Para minimizar el error, necesito el gradiente ($\nabla E$)&rdquo;. En una red simple, $\nabla E$ es fácil de calcular. En una red profunda con millones de pesos, un cálculo ingenuo es computacionalmente intratable.</p></li><li><p>La Retropropagación (Sección V) es el calculador. Dice: &ldquo;Aquí tienes un método rápido y eficiente (usando la Regla de la Cadena y la programación dinámica) para calcular ese $\nabla E$ para todos los millones de pesos&rdquo;.8</p></li><li><p>Juntos, forman el ciclo de entrenamiento: en cada iteración, se realiza un pase hacia adelante (predicción), se calcula el error, Backpropagation calcula el gradiente del error hacia atrás, y el Descenso por Gradiente utiliza ese gradiente para actualizar los pesos hacia adelante.</p></li></ol><h2 id=vi-arquitecturas-de-múltiples-capas-el-perceptrón-multicapa-mlp-y-su-implementación>VI. Arquitecturas de Múltiples Capas: El Perceptrón Multicapa (MLP) y su Implementación<a hidden class=anchor aria-hidden=true href=#vi-arquitecturas-de-múltiples-capas-el-perceptrón-multicapa-mlp-y-su-implementación>#</a></h2><h3 id=a-la-solución-a-la-no-linealidad>A. La Solución a la No Linealidad<a hidden class=anchor aria-hidden=true href=#a-la-solución-a-la-no-linealidad>#</a></h3><p>Armado con un optimizador (GD) y un calculador de gradiente (Backpropagation), el curso regresa a la arquitectura que resuelve la limitación de linealidad del Perceptrón simple: el Perceptrón Multicapa (MLP).1</p><p>Como se estableció en la Sección III, la limitación del Perceptrón simple (como la incapacidad de resolver el XOR) se supera mediante la combinación de dos elementos arquitectónicos clave que definen al MLP:</p><ol><li><p>La inclusión de una o más capas ocultas (capas de neuronas entre la entrada y la salida).</p></li><li><p>El uso de funciones de activación no lineales (como la Sigmoide) en las neuronas de estas capas ocultas.4</p></li></ol><p>Esta combinación permite al MLP &ldquo;doblar&rdquo; y &ldquo;retorcer&rdquo; el espacio de características, creando regiones de decisión no lineales complejas, permitiéndole así aproximar cualquier función continua.</p><h3 id=b-implementación-del-forward-pass>B. Implementación del Forward Pass<a hidden class=anchor aria-hidden=true href=#b-implementación-del-forward-pass>#</a></h3><p>El curso incluye un video crucial que implementa un MLP desde cero usando Python y NumPy.4 Este ejercicio didáctico se centra en el pase hacia adelante (forward pass), que es el proceso que utiliza la red para generar una predicción a partir de una entrada.4</p><p>El análisis de esta implementación revela los siguientes pasos 4:</p><ol><li><p>Definir la Estructura: Se especifica la arquitectura. En el ejemplo del video, se usa una red de 4 nodos de entrada, 3 nodos en la capa oculta y 2 nodos de salida (una arquitectura 4-3-2).4</p></li><li><p>Inicializar las Matrices de Pesos: Los pesos se inicializan aleatoriamente (a menudo usando una distribución normal con media 0) y se almacenan en matrices de NumPy.4</p></li></ol><ul><li><p>Matriz $W_1$ (Input a Hidden): Dimensiones 4x3.</p></li><li><p>Matriz $W_2$ (Hidden a Output): Dimensiones 3x2.</p></li></ul><ol><li><p>Definir la Entrada: Se crea un vector de entrada $X$ (ej. un vector 1x4).4</p></li><li><p>Calcular la Salida de la Capa Oculta ($H$):</p></li></ol><ul><li><p>Se calcula la suma ponderada mediante el producto punto matricial: $Z_1 = X \cdot W_1$.4</p></li><li><p>Se aplica la función de activación no lineal (Sigmoide): $H = \sigma(Z_1)$.4</p></li></ul><ol><li>Calcular la Salida Final ($Y$):</li></ol><ul><li><p>Se calcula la siguiente suma ponderada usando la salida de la capa anterior: $Z_2 = H \cdot W_2$.4</p></li><li><p>Se aplica la activación final para obtener la predicción: $Y = \sigma(Z_2)$.4</p></li></ul><h3 id=c-distinción-crítica-implementación-vs-entrenamiento>C. Distinción Crítica: Implementación vs. Entrenamiento<a hidden class=anchor aria-hidden=true href=#c-distinción-crítica-implementación-vs-entrenamiento>#</a></h3><p>El análisis de este video de implementación 4 revela una decisión pedagógica deliberada y crucial. El video se enfoca exclusivamente en el forward pass (cómo la arquitectura genera una salida). Explícitamente, no implementa el algoritmo de Backpropagation ni la actualización de pesos del Descenso por Gradiente.4</p><p>Esto es fundamental para el estudiante: el curso separa la arquitectura (el flujo de información hacia adelante para la predicción) del entrenamiento (el flujo de error hacia atrás para el aprendizaje). La implementación 4 muestra cómo se construye y ejecuta un MLP. El entrenamiento real requeriría tomar este código y combinarlo con los algoritmos de las Secciones IV (GD) y V (Backpropagation) para calcular el gradiente del error y actualizar iterativamente las matrices $W_1$ y $W_2$.</p><h2 id=vii-arquitecturas-avanzadas-introducción-a-las-redes-neuronales-convolucionales-cnn>VII. Arquitecturas Avanzadas: Introducción a las Redes Neuronales Convolucionales (CNN)<a hidden class=anchor aria-hidden=true href=#vii-arquitecturas-avanzadas-introducción-a-las-redes-neuronales-convolucionales-cnn>#</a></h2><h3 id=a-el-desafío-de-los-datos-multidimensionales>A. El Desafío de los Datos Multidimensionales<a hidden class=anchor aria-hidden=true href=#a-el-desafío-de-los-datos-multidimensionales>#</a></h3><p>La sección final del curso aborda una de las arquitecturas de aprendizaje profundo más influyentes: las Redes Neuronal Convolucionales (CNN).1</p><p>El curso motiva la necesidad de las CNN al exponer las fallas del MLP (Sección VI) cuando se enfrenta a datos de alta dimensionalidad con estructura espacial, como las imágenes.10 Si se quisiera alimentar una imagen modesta de 1000x1000 píxeles a un MLP, primero se debería &ldquo;aplanar&rdquo; en un vector de 1,000,000 de entradas. La primera capa oculta tendría miles de millones de pesos, creando una explosión de parámetros. Peor aún, este aplanamiento destruye toda la información espacial: la red ya no sabe qué píxeles estaban uno al lado del otro.</p><p>Las CNN están diseñadas específicamente para superar estos dos problemas, preservando la información espacial y siendo computacionalmente eficientes.</p><h3 id=b-los-componentes-arquitectónicos-clave-de-una-cnn>B. Los Componentes Arquitectónicos Clave de una CNN<a hidden class=anchor aria-hidden=true href=#b-los-componentes-arquitectónicos-clave-de-una-cnn>#</a></h3><p>Las CNN introducen dos nuevos tipos de capas fundamentales que actúan como un potente extractor de características, analizadas en detalle en el video 10:</p><ol><li>La Capa de Convolución 10:</li></ol><ul><li><p>Kernel (o Filtro/Template): En lugar de neuronas totalmente conectadas, esta capa utiliza un kernel, que es una pequeña matriz de pesos (ej. 3x3 o 5x5). Este kernel está diseñado para detectar una característica local específica, como un borde vertical, una esquina o la curva de un ojo.10</p></li><li><p>Proceso de Convolución: El proceso (técnicamente una correlación cruzada) consiste en deslizar este mismo kernel por toda la imagen de entrada. En cada posición, se realiza una multiplicación elemento a elemento entre el kernel y el parche de la imagen, y los resultados se suman.10</p></li><li><p>Mapa de Características (Feature Map): La salida de esta operación. Es un nuevo &ldquo;mapa&rdquo; 2D que indica dónde se detectó la característica. Las áreas con valores altos (&ldquo;brillantes&rdquo;) en el mapa de características son donde el kernel encontró una coincidencia fuerte.10 Una capa de convolución aprende múltiples kernels en paralelo, buscando múltiples características a la vez.</p></li></ul><ol><li>La Capa de Agrupación (Pooling) 10:</li></ol><ul><li><p>Max Pooling: Esta es la variante más común.10 Desliza una pequeña ventana (ej. 2x2) sobre el mapa de características y, para cada ventana, selecciona únicamente el valor máximo, descartando los demás.10</p></li><li><p>Propósito: Esta operación reduce drásticamente las dimensiones (ancho y alto) del mapa de características, un proceso llamado downsampling. Esto tiene dos beneficios: reduce la complejidad computacional para las capas siguientes y hace que la representación sea más robusta al ruido, reteniendo solo la señal más fuerte de la característica detectada.10</p></li></ul><h3 id=c-principios-fundamentales-de-las-cnn>C. Principios Fundamentales de las CNN<a hidden class=anchor aria-hidden=true href=#c-principios-fundamentales-de-las-cnn>#</a></h3><p>La arquitectura de las CNN se basa en principios que las hacen ideales para la visión por computadora 10:</p><ul><li><p>Invarianza de Posición: Este es el objetivo central. Al aplicar el mismo kernel en toda la imagen, la red aprende a detectar una característica (como un ojo) sin importar dónde aparece en la imagen (arriba, abajo, izquierda o derecha).10 Un MLP tendría que aprender esa característica de nuevo en cada posición posible.</p></li><li><p>Compartición de Parámetros (Parameter Sharing): Este es el &ldquo;truco&rdquo; que dota a las CNN de su eficiencia. En lugar de aprender un peso único para cada píxel (como un MLP), la CNN aprende solo los pesos dentro del kernel (ej. 9 pesos en un kernel de 3x3). Esos mismos 9 pesos se comparten (reutilizan) en cada posición de la imagen. Esto reduce drásticamente el número total de parámetros a aprender, haciendo el entrenamiento más rápido y reduciendo el sobreajuste.</p></li><li><p>Arquitectura Híbrida: Una CNN completa es una arquitectura híbrida. La primera parte de la red (el extractor de características) consiste en una pila de capas de Convolución y Pooling. Estas capas toman la imagen 2D bruta y la transforman progresivamente en un conjunto de mapas de características pequeños y abstractos. La salida de esta pila finalmente se &ldquo;aplana&rdquo; en un vector largo, que luego se alimenta a un MLP estándar (como el de la Sección VI) que actúa como el clasificador final.10 En esencia, la CNN aprende automáticamente a extraer las características relevantes, liberando al MLP de tener que hacerlo desde datos de píxeles brutos.</p></li></ul><h3 id=elemento-infográfico-tabla-3-anatomía-de-una-red-neuronal-convolucional-cnn>Elemento Infográfico (Tabla 3): Anatomía de una Red Neuronal Convolucional (CNN)<a hidden class=anchor aria-hidden=true href=#elemento-infográfico-tabla-3-anatomía-de-una-red-neuronal-convolucional-cnn>#</a></h3><p><img loading=lazy src="https://github.com/Ancordss/Ancordss.github.io/blob/main/static/info/image-2.png?raw=true" alt="tabla 3"></p><h2 id=viii-síntesis-y-conclusión-del-curso>VIII. Síntesis y Conclusión del Curso<a hidden class=anchor aria-hidden=true href=#viii-síntesis-y-conclusión-del-curso>#</a></h2><p>El curso intensivo de redes neuronales de Irving Vasquez 1 proporciona una trayectoria de aprendizaje coherente y rigurosa, guiando al estudiante desde los fundamentos filosóficos de la IA hasta las arquitecturas modernas de aprendizaje profundo.</p><p>La síntesis del curso revela una narrativa lógica:</p><ol><li><p>Comienza con la neurona lógica estática (McCulloch-Pitts), que puede modelar la lógica pero no puede aprender.5</p></li><li><p>La limitación del no-aprendizaje se supera con el Perceptrón y sus pesos modificables.1</p></li><li><p>La limitación del Perceptrón (linealidad) se supera con el MLP y sus activaciones no lineales.6</p></li><li><p>El problema de cómo entrenar un MLP se define como un problema de optimización, resuelto por el Descenso por Gradiente.3</p></li><li><p>El desafío computacional del Descenso por Gradiente (el cálculo de $\nabla E$) se resuelve con el algoritmo de Backpropagation.8</p></li><li><p>Finalmente, la limitación del MLP (datos de alta dimensionalidad como imágenes) se supera con la arquitectura especializada de las CNN.10</p></li></ol><p>Como se indica en la presentación del curso, esta lista de reproducción de 25 videos sirve como un pilar fundamental. Al cubrir la teoría matemática (GD, Backpropagation) y la implementación práctica (Python, NumPy, MLP, CNN), el curso proporciona la base indispensable sobre la cual se construyen todos los temas avanzados del Deep Learning.11 El estudiante que completa este currículo no solo sabe cómo usar las redes neuronales, sino que entiende por qué y cómo funcionan a nivel fundamental.</p><h4 id=fuentes-citadas>Fuentes citadas<a hidden class=anchor aria-hidden=true href=#fuentes-citadas>#</a></h4><ol><li><p>Introducción a las redes neuronales - YouTube, acceso: octubre 24, 2025, <a href="https://youtube.com/playlist?list=PLVo0_3_ZKpuBeGJQneleWT0vg4aPqTveF">https://youtube.com/playlist?list=PLVo0_3_ZKpuBeGJQneleWT0vg4aPqTveF</a></p></li><li><p>Inteligencia artificial y redes neuronales - YouTube, acceso: octubre 24, 2025, <a href="https://www.youtube.com/watch?v=wZh3ReAxAaU">https://www.youtube.com/watch?v=wZh3ReAxAaU</a></p></li><li><p>Descenso por gradiente explicado a detalle - YouTube, acceso: octubre 24, 2025, <a href="https://www.youtube.com/watch?v=cwkGzEXUuMs">https://www.youtube.com/watch?v=cwkGzEXUuMs</a></p></li><li><p>Implementación de la red neuronal multicapa (MLP) en Python - YouTube, acceso: octubre 24, 2025, <a href="https://www.youtube.com/watch?v=kp1K0QaY9kY">https://www.youtube.com/watch?v=kp1K0QaY9kY</a></p></li><li><p>Modelo McCulloch y Pitts: La primer neurona artificial - YouTube, acceso: octubre 24, 2025, <a href="https://www.youtube.com/watch?v=JaLMcVO1CCE">https://www.youtube.com/watch?v=JaLMcVO1CCE</a></p></li><li><p>¿Cuál es la capacidad de una red neuronal? - YouTube, acceso: octubre 24, 2025, <a href="https://www.youtube.com/watch?v=JCA2DDOkweE">https://www.youtube.com/watch?v=JCA2DDOkweE</a></p></li><li><p>El Perceptrón - Descenso por Gradiente - YouTube, acceso: octubre 24, 2025, <a href="https://www.youtube.com/watch?v=ytzyN1v7-6M">https://www.youtube.com/watch?v=ytzyN1v7-6M</a></p></li><li><p>Backpropagation (Retropropagación) - YouTube, acceso: octubre 24, 2025, <a href="https://www.youtube.com/watch?v=bJFM9rvpwaY">https://www.youtube.com/watch?v=bJFM9rvpwaY</a></p></li><li><p>Algoritmo Backpropagation - YouTube, acceso: octubre 24, 2025, <a href="https://www.youtube.com/watch?v=CdkgZJS5Caw">https://www.youtube.com/watch?v=CdkgZJS5Caw</a></p></li><li><p>Redes neuronales convolucionales a detalle - YouTube, acceso: octubre 24, 2025, <a href="https://www.youtube.com/watch?v=Xk2HdJQjdyc">https://www.youtube.com/watch?v=Xk2HdJQjdyc</a></p></li><li><p>Introducción a las redes neuronales - Presentación del curso - YouTube, acceso: octubre 24, 2025, <a href="https://www.youtube.com/watch?v=cF0cqcw_LSw">https://www.youtube.com/watch?v=cF0cqcw_LSw</a></p></li></ol></div><footer class=post-footer><ul class=post-tags><li><a href=https://ancordss.github.io/tags/fast/>Fast</a></li><li><a href=https://ancordss.github.io/tags/blogging/>Blogging</a></li></ul><nav class=paginav><a class=next href=https://ancordss.github.io/post/blogging/cfn-modules1/><span class=title>Next Page »</span><br><span>Streamlining AWS CloudFormation with cfn-modules: A Time-Saving Solution</span></a></nav><div class=share-buttons><a target=_blank rel="noopener noreferrer" aria-label="share Infografia Redes Neuronales on twitter" href="https://twitter.com/intent/tweet/?text=Infografia%20Redes%20Neuronales&amp;url=https%3a%2f%2fancordss.github.io%2fpost%2fia%2f&amp;hashtags=fast%2cBlogging"><svg viewBox="0 0 512 512"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H62.554c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892zM195.519 424.544c135.939.0 210.268-112.643 210.268-210.268.0-3.218.0-6.437-.153-9.502 14.406-10.421 26.973-23.448 36.935-38.314-13.18 5.824-27.433 9.809-42.452 11.648 15.326-9.196 26.973-23.602 32.49-40.92-14.252 8.429-30.038 14.56-46.896 17.931-13.487-14.406-32.644-23.295-53.946-23.295-40.767.0-73.87 33.104-73.87 73.87.0 5.824.613 11.494 1.992 16.858-61.456-3.065-115.862-32.49-152.337-77.241-6.284 10.881-9.962 23.601-9.962 37.088.0 25.594 13.027 48.276 32.95 61.456-12.107-.307-23.448-3.678-33.41-9.196v.92c0 35.862 25.441 65.594 59.311 72.49-6.13 1.686-12.72 2.606-19.464 2.606-4.751.0-9.348-.46-13.946-1.38 9.349 29.426 36.628 50.728 68.965 51.341-25.287 19.771-57.164 31.571-91.8 31.571-5.977.0-11.801-.306-17.625-1.073 32.337 21.15 71.264 33.41 112.95 33.41z"/></svg>
</a><a target=_blank rel="noopener noreferrer" aria-label="share Infografia Redes Neuronales on linkedin" href="https://www.linkedin.com/shareArticle?mini=true&amp;url=https%3a%2f%2fancordss.github.io%2fpost%2fia%2f&amp;title=Infografia%20Redes%20Neuronales&amp;summary=Infografia%20Redes%20Neuronales&amp;source=https%3a%2f%2fancordss.github.io%2fpost%2fia%2f"><svg viewBox="0 0 512 512"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H62.554c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892zM160.461 423.278V197.561h-75.04v225.717h75.04zm270.539.0V293.839c0-69.333-37.018-101.586-86.381-101.586-39.804.0-57.634 21.891-67.617 37.266v-31.958h-75.021c.995 21.181.0 225.717.0 225.717h75.02V297.222c0-6.748.486-13.492 2.474-18.315 5.414-13.475 17.767-27.434 38.494-27.434 27.135.0 38.007 20.707 38.007 51.037v120.768H431zM123.448 88.722C97.774 88.722 81 105.601 81 127.724c0 21.658 16.264 39.002 41.455 39.002h.484c26.165.0 42.452-17.344 42.452-39.002-.485-22.092-16.241-38.954-41.943-39.002z"/></svg>
</a><a target=_blank rel="noopener noreferrer" aria-label="share Infografia Redes Neuronales on reddit" href="https://reddit.com/submit?url=https%3a%2f%2fancordss.github.io%2fpost%2fia%2f&title=Infografia%20Redes%20Neuronales"><svg viewBox="0 0 512 512"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H62.554c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892zM446 265.638c0-22.964-18.616-41.58-41.58-41.58-11.211.0-21.361 4.457-28.841 11.666-28.424-20.508-67.586-33.757-111.204-35.278l18.941-89.121 61.884 13.157c.756 15.734 13.642 28.29 29.56 28.29 16.407.0 29.706-13.299 29.706-29.701.0-16.403-13.299-29.702-29.706-29.702-11.666.0-21.657 6.792-26.515 16.578l-69.105-14.69c-1.922-.418-3.939-.042-5.585 1.036-1.658 1.073-2.811 2.761-3.224 4.686l-21.152 99.438c-44.258 1.228-84.046 14.494-112.837 35.232-7.468-7.164-17.589-11.591-28.757-11.591-22.965.0-41.585 18.616-41.585 41.58.0 16.896 10.095 31.41 24.568 37.918-.639 4.135-.99 8.328-.99 12.576.0 63.977 74.469 115.836 166.33 115.836s166.334-51.859 166.334-115.836c0-4.218-.347-8.387-.977-12.493 14.564-6.47 24.735-21.034 24.735-38.001zM326.526 373.831c-20.27 20.241-59.115 21.816-70.534 21.816-11.428.0-50.277-1.575-70.522-21.82-3.007-3.008-3.007-7.882.0-10.889 3.003-2.999 7.882-3.003 10.885.0 12.777 12.781 40.11 17.317 59.637 17.317 19.522.0 46.86-4.536 59.657-17.321 3.016-2.999 7.886-2.995 10.885.008 3.008 3.011 3.003 7.882-.008 10.889zm-5.23-48.781c-16.373.0-29.701-13.324-29.701-29.698.0-16.381 13.328-29.714 29.701-29.714 16.378.0 29.706 13.333 29.706 29.714.0 16.374-13.328 29.698-29.706 29.698zM160.91 295.348c0-16.381 13.328-29.71 29.714-29.71 16.369.0 29.689 13.329 29.689 29.71.0 16.373-13.32 29.693-29.689 29.693-16.386.0-29.714-13.32-29.714-29.693z"/></svg>
</a><a target=_blank rel="noopener noreferrer" aria-label="share Infografia Redes Neuronales on facebook" href="https://facebook.com/sharer/sharer.php?u=https%3a%2f%2fancordss.github.io%2fpost%2fia%2f"><svg viewBox="0 0 512 512"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H342.978V319.085h66.6l12.672-82.621h-79.272v-53.617c0-22.603 11.073-44.636 46.58-44.636H425.6v-70.34s-32.71-5.582-63.982-5.582c-65.288.0-107.96 39.569-107.96 111.204v62.971h-72.573v82.621h72.573V512h-191.104c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892z"/></svg>
</a><a target=_blank rel="noopener noreferrer" aria-label="share Infografia Redes Neuronales on whatsapp" href="https://api.whatsapp.com/send?text=Infografia%20Redes%20Neuronales%20-%20https%3a%2f%2fancordss.github.io%2fpost%2fia%2f"><svg viewBox="0 0 512 512"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H62.554c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892zm-58.673 127.703c-33.842-33.881-78.847-52.548-126.798-52.568-98.799.0-179.21 80.405-179.249 179.234-.013 31.593 8.241 62.428 23.927 89.612l-25.429 92.884 95.021-24.925c26.181 14.28 55.659 21.807 85.658 21.816h.074c98.789.0 179.206-80.413 179.247-179.243.018-47.895-18.61-92.93-52.451-126.81zM263.976 403.485h-.06c-26.734-.01-52.954-7.193-75.828-20.767l-5.441-3.229-56.386 14.792 15.05-54.977-3.542-5.637c-14.913-23.72-22.791-51.136-22.779-79.287.033-82.142 66.867-148.971 149.046-148.971 39.793.014 77.199 15.531 105.329 43.692 28.128 28.16 43.609 65.592 43.594 105.4-.034 82.149-66.866 148.983-148.983 148.984zm81.721-111.581c-4.479-2.242-26.499-13.075-30.604-14.571-4.105-1.495-7.091-2.241-10.077 2.241-2.986 4.483-11.569 14.572-14.182 17.562-2.612 2.988-5.225 3.364-9.703 1.12-4.479-2.241-18.91-6.97-36.017-22.23C231.8 264.15 222.81 249.484 220.198 245s-.279-6.908 1.963-9.14c2.016-2.007 4.48-5.232 6.719-7.847 2.24-2.615 2.986-4.484 4.479-7.472 1.493-2.99.747-5.604-.374-7.846-1.119-2.241-10.077-24.288-13.809-33.256-3.635-8.733-7.327-7.55-10.077-7.688-2.609-.13-5.598-.158-8.583-.158-2.986.0-7.839 1.121-11.944 5.604-4.105 4.484-15.675 15.32-15.675 37.364.0 22.046 16.048 43.342 18.287 46.332 2.24 2.99 31.582 48.227 76.511 67.627 10.685 4.615 19.028 7.371 25.533 9.434 10.728 3.41 20.492 2.929 28.209 1.775 8.605-1.285 26.499-10.833 30.231-21.295 3.732-10.464 3.732-19.431 2.612-21.298-1.119-1.869-4.105-2.99-8.583-5.232z"/></svg>
</a><a target=_blank rel="noopener noreferrer" aria-label="share Infografia Redes Neuronales on telegram" href="https://telegram.me/share/url?text=Infografia%20Redes%20Neuronales&amp;url=https%3a%2f%2fancordss.github.io%2fpost%2fia%2f"><svg viewBox="2 2 28 28"><path d="M26.49 29.86H5.5a3.37 3.37.0 01-2.47-1 3.35 3.35.0 01-1-2.47V5.48A3.36 3.36.0 013 3 3.37 3.37.0 015.5 2h21A3.38 3.38.0 0129 3a3.36 3.36.0 011 2.46V26.37a3.35 3.35.0 01-1 2.47 3.38 3.38.0 01-2.51 1.02zm-5.38-6.71a.79.79.0 00.85-.66L24.73 9.24a.55.55.0 00-.18-.46.62.62.0 00-.41-.17q-.08.0-16.53 6.11a.59.59.0 00-.41.59.57.57.0 00.43.52l4 1.24 1.61 4.83a.62.62.0 00.63.43.56.56.0 00.4-.17L16.54 20l4.09 3A.9.9.0 0021.11 23.15zM13.8 20.71l-1.21-4q8.72-5.55 8.78-5.55c.15.0.23.0.23.16a.18.18.0 010 .06s-2.51 2.3-7.52 6.8z"/></svg></a></div></footer></article></main><footer class=footer><span>&copy; 2025 <a href=https://ancordss.github.io/>Ancordss-Blog!</a></span>
<span>Powered by
<a href=https://gohugo.io/ rel="noopener noreferrer" target=_blank>Hugo</a> &
        <a href=https://git.io/hugopapermod rel=noopener target=_blank>PaperMod</a></span></footer><a href=#top aria-label="go to top" title="Go to Top (Alt + G)" class=top-link id=top-link accesskey=g><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 12 6" fill="currentcolor"><path d="M12 6H0l6-6z"/></svg>
</a><script>let menu=document.getElementById("menu");menu&&(menu.scrollLeft=localStorage.getItem("menu-scroll-position"),menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft)}),document.querySelectorAll('a[href^="#"]').forEach(e=>{e.addEventListener("click",function(e){e.preventDefault();var t=this.getAttribute("href").substr(1);window.matchMedia("(prefers-reduced-motion: reduce)").matches?document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView():document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView({behavior:"smooth"}),t==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${t}`)})})</script><script>var mybutton=document.getElementById("top-link");window.onscroll=function(){document.body.scrollTop>800||document.documentElement.scrollTop>800?(mybutton.style.visibility="visible",mybutton.style.opacity="1"):(mybutton.style.visibility="hidden",mybutton.style.opacity="0")}</script><script>document.getElementById("theme-toggle").addEventListener("click",()=>{document.body.className.includes("dark")?(document.body.classList.remove("dark"),localStorage.setItem("pref-theme","light")):(document.body.classList.add("dark"),localStorage.setItem("pref-theme","dark"))})</script><script>document.querySelectorAll("pre > code").forEach(e=>{const n=e.parentNode.parentNode,t=document.createElement("button");t.classList.add("copy-code"),t.innerText="copy";function s(){t.innerText="copied!",setTimeout(()=>{t.innerText="copy"},2e3)}t.addEventListener("click",t=>{if("clipboard"in navigator){navigator.clipboard.writeText(e.textContent),s();return}const n=document.createRange();n.selectNodeContents(e);const o=window.getSelection();o.removeAllRanges(),o.addRange(n);try{document.execCommand("copy"),s()}catch{}o.removeRange(n)}),n.classList.contains("highlight")?n.appendChild(t):n.parentNode.firstChild==n||(e.parentNode.parentNode.parentNode.parentNode.parentNode.nodeName=="TABLE"?e.parentNode.parentNode.parentNode.parentNode.parentNode.appendChild(t):e.parentNode.appendChild(t))})</script></body></html>